{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                               ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3135, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model.forward(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        ...,\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.view(images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3168, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model.forward(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5133,  0.7694],\n",
      "        [-1.0839,  0.2199]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad= True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.2899, 0.5920],\n",
      "        [1.1749, 0.0484]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y=x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(3, 5, (3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x000001BDEF357978>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0263, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z=y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7566,  0.3847],\n",
      "        [-0.5420,  0.1100]])\n",
      "tensor([[ 0.7566,  0.3847],\n",
      "        [-0.5420,  0.1100]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn. Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logits= model(images)\n",
    "loss = criterion(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before backward pass: \n",
      " None\n",
      "after backward pass: \n",
      " tensor([[-0.0018, -0.0018, -0.0018,  ..., -0.0018, -0.0018, -0.0018],\n",
      "        [-0.0004, -0.0004, -0.0004,  ..., -0.0004, -0.0004, -0.0004],\n",
      "        [ 0.0028,  0.0028,  0.0028,  ...,  0.0028,  0.0028,  0.0028],\n",
      "        ...,\n",
      "        [-0.0026, -0.0026, -0.0026,  ..., -0.0026, -0.0026, -0.0026],\n",
      "        [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
      "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002]])\n"
     ]
    }
   ],
   "source": [
    "print('before backward pass: \\n', model[0].weight.grad)\n",
    "loss.backward()\n",
    "print('after backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim \n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial weights Parameter containing:\n",
      "tensor([[-0.0040, -0.0283,  0.0109,  ..., -0.0199,  0.0230,  0.0109],\n",
      "        [-0.0082,  0.0186,  0.0187,  ...,  0.0045, -0.0180, -0.0110],\n",
      "        [-0.0095, -0.0167,  0.0326,  ...,  0.0017, -0.0172,  0.0044],\n",
      "        ...,\n",
      "        [-0.0066, -0.0308, -0.0186,  ...,  0.0165,  0.0070, -0.0268],\n",
      "        [-0.0191, -0.0007,  0.0247,  ...,  0.0187,  0.0229, -0.0193],\n",
      "        [-0.0128,  0.0061,  0.0048,  ..., -0.0283, -0.0338,  0.0156]],\n",
      "       requires_grad=True)\n",
      "gradient  tensor([[-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
      "        [ 0.0024,  0.0024,  0.0024,  ...,  0.0024,  0.0024,  0.0024],\n",
      "        [ 0.0004,  0.0004,  0.0004,  ...,  0.0004,  0.0004,  0.0004],\n",
      "        ...,\n",
      "        [ 0.0008,  0.0008,  0.0008,  ...,  0.0008,  0.0008,  0.0008],\n",
      "        [ 0.0025,  0.0025,  0.0025,  ...,  0.0025,  0.0025,  0.0025],\n",
      "        [-0.0009, -0.0009, -0.0009,  ..., -0.0009, -0.0009, -0.0009]])\n"
     ]
    }
   ],
   "source": [
    "print('initial weights', model[0].weight)\n",
    "imagse, labels= next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "\n",
    "#clearing the gradients \n",
    "optimizer.zero_grad()\n",
    "\n",
    "#forward pass-> backward pass-> update weights\n",
    "output = model.forward(images)\n",
    "loss= criterion(output, labels)\n",
    "\n",
    "loss.backward()\n",
    "print('gradient ', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weights Parameter containing:\n",
      "tensor([[-0.0040, -0.0283,  0.0109,  ..., -0.0199,  0.0230,  0.0109],\n",
      "        [-0.0083,  0.0186,  0.0187,  ...,  0.0045, -0.0180, -0.0110],\n",
      "        [-0.0095, -0.0167,  0.0326,  ...,  0.0017, -0.0172,  0.0044],\n",
      "        ...,\n",
      "        [-0.0066, -0.0308, -0.0186,  ...,  0.0165,  0.0070, -0.0268],\n",
      "        [-0.0191, -0.0008,  0.0247,  ...,  0.0186,  0.0228, -0.0193],\n",
      "        [-0.0128,  0.0061,  0.0048,  ..., -0.0283, -0.0338,  0.0156]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()\n",
    "print('update weights', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 2.231606663671384\n",
      "training loss 1.9745478433078285\n",
      "training loss 1.5365359851800557\n",
      "training loss 1.106944273720418\n",
      "training loss 0.8393701278070397\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion= nn.NLLLoss()\n",
    "optimizer= optim.SGD(model.parameters(), lr= 0.001)\n",
    "\n",
    "#epochs\n",
    "epoch= 5\n",
    "\n",
    "for e in range(epoch):\n",
    "    running_loss= 0 \n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1) #flatten the images\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output= model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"training loss {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1,784)\n",
    "\n",
    "with torch.no_grad(): #tun off gradients \n",
    "    logps= model.forward(img)\n",
    "    \n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
